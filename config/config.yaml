server:
  port: 8080
  mode: debug  # debug, release

database:
  host: localhost
  port: 5432
  user: postgres
  password: ${DB_PASSWORD}
  dbname: x_bot
  sslmode: disable
  max_open_conns: 25
  max_idle_conns: 5
  conn_max_lifetime: 5m

twitter:
  api_key: ${TWITTER_API_KEY}
  api_secret: ${TWITTER_API_SECRET}
  access_token: ${TWITTER_ACCESS_TOKEN}
  access_secret: ${TWITTER_ACCESS_SECRET}
  bearer_token: ${TWITTER_BEARER_TOKEN}
  timeout: 30s
  rate_limit_wait: 15m

llm:
  # 支持的 provider: openai, gemini, groq
  # OpenAI 配置示例:
  #   provider: openai
  #   api_key: ${OPENAI_API_KEY}
  #   model: gpt-4o-mini
  #   base_url: https://api.openai.com/v1
  # 
  # 获取API Key https://aistudio.google.com/app/apikey
  # Google Gemini 配置示例:
  #   provider: gemini
  #   api_key: ${GEMINI_API_KEY}
  #   model: gemini-1.5-flash
  #   base_url: https://generativelanguage.googleapis.com/v1beta
  #
  # Groq 配置示例 (免费):
  #   provider: openai
  #   api_key: ${GROQ_API_KEY}
  #   model: llama-3.1-8b-instant
  #   base_url: https://api.groq.com/openai/v1

  provider: gemini
  api_key: ${GEMINI_API_KEY}
  model: gemini-2.5-flash
  base_url: https://generativelanguage.googleapis.com/v1beta
  timeout: 30s
  max_retries: 3

workflow:
  default_tweet_count: 10
  reply_interval: 60s
  max_daily_replies: 100
  enable_scheduler: false
  schedule: "0 */2 * * *"  # 每2小时执行一次

log:
  level: debug  # debug, info, warn, error
  format: json  # json, console

